\`--- title: "lab3" output: html_document ---

### Work breakdown:

Problem 1: Viktoriya Kibyeryeva\
Problem 2: Arsen Botkso\
Problem 3: Nazar Mykolaichuk\

# Problem 1

```{r}
team_id <- 33
set.seed(team_id)
sample_sizes <- c(50, 100, 200, 500, 1000)
alphas <- c(0.1, 0.05, 0.01)
num_repetitions <- c(100, 500, 1000)
theta <- team_id / 10
lambda <- 1 / theta

```

The distribution:\
$X \sim E(\lambda)$\
It's mean:\
$\mu = 1/ \lambda$\
Then a good estimate for $\theta = 1/ \lambda$ is sample mean $\overline{X}$.\

We need to form confidence intervals.

### 1.Using exact distribution of the statistics $2\lambda n \overline{X}$

$X_i$ - iid rvs, so $S_x \sim G(n, \lambda)$\
For exponential distribution, $M_x(t) = (1 - t/\lambda)^{-1}$\
Because variables are independent, mgf of the sum is the product of mgfs\
$M_s(t) = (1-t/\lambda)^{-n}$\
$Y = 2\lambda n \overline{X} \$\$S = n \* \overline{X}$\
Then $Y = 2\lambda S$\
$M_Y(t) = E(t^{Y}) = E(t^{2\lambda S}) = M_S(2\lambda t) = (1-2\lambda t/\lambda))^{-n} = (1-2t)^{-n}$\
We can recognize the formula of mgf of Chi-squared distribution\
So $Y\sim \chi_{2n}^2$\
Constructing confidence interval:\
$P(\chi_{1-\alpha/2,2n}^2\leq Y\leq\chi_{\alpha/2,2n}^2)=1-\alpha$\
$P(\chi_{1-\alpha/2,2n}^2\leq 2n\overline{X}/\theta\leq\chi_{\alpha/2,2n}^2)=1-\alpha$\
So our confidence interval is $[2n\overline{X}/\chi_{\alpha/2,2n}^2, 2n\overline{X}/(\chi_{1-\alpha/2,2n}^2]$\

### 2. Using Normal approximation and unknown variance

$P(|\theta-\overline{X}|\leq z_{\beta}\theta/\sqrt{n}) = P(|Z|\leq z_{\beta}) = 2\beta-1$

### 3. Solving above for theta

$(|\theta-\overline{X}|\leq z_{\beta}\theta/\sqrt{n}) = P(-z_{\beta}\theta/\sqrt{n} \leq \overline{X}- \theta\leq z_{\beta}\theta/\sqrt{n}) = P(-z_{\beta}\theta/\sqrt{n} +\theta \leq \overline{X}\leq z_{\beta}\theta/\sqrt{n}+\theta) = P(\overline{X}/(1 + z_{\beta}/\sqrt{n}) \leq \theta \leq \overline{X}/(1 - z_{\beta}/\sqrt{n}))$\
So confidence interval is\
$[\overline{X}/(1+z/\sqrt{n}), \overline{X}/(1-z/\sqrt{n})]$

### 4. Using student distribution

We approximate standard error as $s = \sqrt{\Sigma(X_i-\overline{X})^2/(n-1)}$ So our confidence interval is $\overline{X}\pm t_{n-1, \alpha/2} * s/\sqrt{n}$

```{r}

results <- data.frame()

for (n in num_repetitions){
  for (size in sample_sizes){
    # Creating sample
    data <- matrix(rexp(size * n, rate = lambda), nrow = size, ncol = n)
    x_bar <- colMeans(data)
    s <- apply(data, 2, sd)
    for (alpha in alphas) {
    z_crit <- qnorm(1 - alpha / 2)
    t_crit <- qt(1 - alpha / 2, df = size - 1)
    chi_lower <- qchisq(alpha / 2, df = 2 * size)
    chi_upper <- qchisq(1 - alpha / 2, df = 2 * size)
    # Method 1
    m1_lower <- (2 * size * x_bar) / chi_upper
    m1_upper <- (2 * size * x_bar) / chi_lower
    # Method 2
    se_true <- theta / sqrt(size)
    m2_lower <- x_bar - z_crit * se_true
    m2_upper <- x_bar + z_crit * se_true
    # Method 3
    denom_plus <- 1 + (z_crit / sqrt(size))
    denom_minus <- 1 - (z_crit / sqrt(size))
    m3_lower <- x_bar / denom_plus
    m3_upper <- x_bar / denom_minus
    se_est <- s / sqrt(size)
    # Method 4
    m4_lower <- x_bar - t_crit * se_est
    m4_upper <- x_bar + t_crit * se_est
    # Calculating the results
    cov1 <- mean(m1_lower <= theta & theta <= m1_upper)
    cov2 <- mean(m2_lower <= theta & theta <= m2_upper)
    cov3 <- mean(m3_lower <= theta & theta <= m3_upper)
    cov4 <- mean(m4_lower <= theta & theta <= m4_upper)
    len1 <- mean(m1_upper - m1_lower)
    len2 <- mean(m2_upper - m2_lower)
    len3 <- mean(m3_upper - m3_lower)
    len4 <- mean(m4_upper - m4_lower)
    results <- rbind(results, data.frame(
        Reps_m = n,
        Size_n = size,
        Alpha = alpha,
        Method = c("1.Exact", "2.Norm(theta)", "3.Norm(se)", "4.Student-t"),
        Coverage = c(cov1, cov2, cov3, cov4),
        AvgLength = c(len1, len2, len3, len4)
      ))
    }
  }
}
results_sorted <- results[order(results$Method, results$Size_n, results$Reps_m), ]

print(format(results_sorted, digits = 4))
```

```{r}
precision_data <- results[, c("Reps_m", "Size_n", "Alpha", "Method", "AvgLength")]
stats <- reshape(precision_data, 
                          idvar = c("Reps_m", "Size_n", "Alpha"), 
                          timevar = "Method", 
                          direction = "wide")

colnames(stats) <- gsub("AvgLength.", "", colnames(stats))

stats <- stats[order(stats$Reps_m, stats$Size_n, stats$Alpha), ]

print(stats, row.names = FALSE)
```

```{r}
coverage_data <- results[, c("Reps_m", "Size_n", "Alpha", "Method", "Coverage")]

cov <- reshape(coverage_data, 
                        idvar = c("Reps_m", "Size_n", "Alpha"), 
                        timevar = "Method", 
                        direction = "wide")

colnames(cov) <- gsub("Coverage.", "", colnames(cov))

cov$Target <- 1 - cov$Alpha

cols <- c("Reps_m", "Size_n", "Alpha", "Target", setdiff(names(cov), c("Reps_m", "Size_n", "Alpha", "Target")))
cov <- cov[, cols]

cov <- cov[order(cov$Reps_m, cov$Size_n, cov$Alpha), ]

print(cov, row.names = FALSE)
```

```{r}
plot_reps <- max(num_repetitions)
plot_alpha <- 0.05
plot_data <- subset(results, Reps_m == plot_reps & Alpha == plot_alpha)

methods <- unique(plot_data$Method)
colors <- c("red", "blue", "darkgreen", "purple")
pch_types <- 1:4

par(mfrow = c(1, 2)) 

y_min <- min(plot_data$Coverage, 1 - plot_alpha) - 0.02
y_max <- max(plot_data$Coverage, 1 - plot_alpha) + 0.02

plot(range(sample_sizes), c(y_min, y_max), type = "n",
     xlab = "Sample Size (n)", ylab = "Coverage Probability",
     main = paste("Coverage (Alpha =", plot_alpha, ")"))

abline(h = 1 - plot_alpha, col = "gray", lty = 2, lwd = 2)

for(i in 1:length(methods)){
  sub_d <- subset(plot_data, Method == methods[i])
  sub_d <- sub_d[order(sub_d$Size_n), ]
  lines(sub_d$Size_n, sub_d$Coverage, col = colors[i], type = "b", pch = pch_types[i], lwd = 1.5)
}

legend("bottomright", legend = methods, col = colors, pch = pch_types, lty = 1, cex = 0.8, bg = "white")

y_rng <- range(plot_data$AvgLength, na.rm = TRUE)

plot(range(sample_sizes), y_rng, type = "n",
     xlab = "Sample Size (n)", ylab = "Average Length",
     main = "Interval Length (Precision)")

for(i in 1:length(methods)){
  sub_d <- subset(plot_data, Method == methods[i])
  sub_d <- sub_d[order(sub_d$Size_n), ]
  lines(sub_d$Size_n, sub_d$AvgLength, col = colors[i], type = "b", pch = pch_types[i], lwd = 1.5)
}

legend("topright", legend = methods, col = colors, pch = pch_types, lty = 1, cex = 0.8, bg = "white")

```

As we can see, using exact distribution demonstrates the most stable performance.\
Approximation with normal distribution gives a bit worse results, both in the case of using unknown variance and estimating it using sample standard error.\
Approximation with Student distribution works the worst at smaller sample sizes, but as sizes get bigger it's performance increases.\
Theoretically, the best approach is using exact distribution because it is guaranteed to give the right result, but we can see, that as sample sizes get bigger all of the approaches start performing really well.

# Problem 2

In this problem we repeat the simulation from Problem 1, but for the Poisson distribution.

For the Poisson distribution: E(X) = $\theta$ , Var(X) = $\theta$

Sample mean:$$
\bar X = \frac{1}{n} \sum_{i=1}^n X_i
$$

By the Central Limit Theorem, for large $n$, $$\bar X \approx N\left(\theta,\ \frac{\theta}{n}\right).$$

### 2) Using the normal approximation for $\bar X$

$$
\mathbb{E}[\bar X] = \theta, \quad \operatorname{Var}(\bar X) = \frac{\theta}{n}.
$$

Using the Central Limit Theorem, we approximate the distribution of $\bar X$ by $$
\bar X \approx N\left(\mu, \sigma^2\right), \quad  \mu = \theta,\ \sigma^2 = \frac{\theta}{n}.
$$

$$
Z = \frac{\bar X - \theta}{\sqrt{\theta/n}} 
$$ and use the fact that it is approximately standard normal $N(0,1)$ to get

$$
P\left( \left|\bar X - \theta\right| \le z_\beta \sqrt{\frac{\theta}{n}} \right)
= P\left( |Z| \le z_\beta \right)
= 2\beta - 1.
$$

### 3) Solving above for $\theta$

We have the inequality $$
|\bar X - \theta| \le z_\beta \sqrt{\frac{\theta}{n}}.
$$

Squaring and rearranging, we get a quadratic inequality in $\theta$: $$
(\bar X - \theta)^2 \le z_\beta^2 \frac{\theta}{n}
$$ So we can rewrite it like this: $$
\theta^2 - \left(2\bar X + \frac{z_\beta^2}{n}\right)\theta + \bar X^2 \le 0.
$$

The roots of this quadratic equation are $$
\theta_{1,2} =
\frac{2\bar X + \frac{z_\beta^2}{n} \pm
\sqrt{\left(2\bar X + \frac{z_\beta^2}{n}\right)^2 - 4\bar X^2}}{2}.
$$

So the confidence interval is $[\theta_1,\ \theta_2],$

### 4) Using student distribution

We approximate the standard error using the sample standard deviation $s = \sqrt{\Sigma(X_i-\overline{X})^2/(n-1)}$

So our confidence interval is

$\overline{X} \pm t_{n-1,\alpha/2}\,\dfrac{s}{\sqrt{n}}$

```{r}

results_poisson <- data.frame()

for (n in num_repetitions){
  for (size in sample_sizes){
    # Creating sample
    data <- matrix(rpois(size * n, lambda = theta), nrow = size, ncol = n)
    x_bar <- colMeans(data)
    s <- apply(data, 2, sd)
    for (alpha in alphas) {
    z_crit <- qnorm(1 - alpha / 2)
    t_crit <- qt(1 - alpha / 2, df = size - 1)

    # Method 2
    se_true <- sqrt(theta / size)
    m2_lower <- x_bar - z_crit * se_true 
    m2_upper <- x_bar + z_crit * se_true
    # Method 3
    z2_over_n <- (z_crit^2) / size 
    D <- (2 * x_bar + z2_over_n)^2 - 4 * x_bar^2 
    D[D < 0] <- 0 
    sqrtD <- sqrt(D)
    theta_L <- (2 * x_bar + z2_over_n - sqrtD) / 2 
    theta_U <- (2 * x_bar + z2_over_n + sqrtD) / 2 
    m3_lower <- pmax(theta_L, 0) # θ ≥ 0 
    m3_upper <- theta_U
    # Method 4
    se_est <- s / sqrt(size) 
    m4_lower <- x_bar - t_crit * se_est 
    m4_upper <- x_bar + t_crit * se_est
    # Calculating the results
    cov1 <- mean(m2_lower <= theta & theta <= m2_upper)
    cov2 <- mean(m3_lower <= theta & theta <= m3_upper)
    cov3 <- mean(m4_lower <= theta & theta <= m4_upper)

    len1 <- mean(m2_upper - m2_lower)
    len2 <- mean(m3_upper - m3_lower)
    len3 <- mean(m4_upper - m4_lower)
    results_poisson <- rbind(results_poisson, data.frame(
        Reps_m = n,
        Size_n = size,
        Alpha = alpha,
        Method = c("1.Norm(theta)", "2.Norm(quadratic)", "3.Student-t"),
        Coverage = c(cov1, cov2, cov3),
        AvgLength = c(len1, len2, len3)
      ))
    }
  }
}
results_sorted <- results[order(results$Method, results$Size_n, results$Reps_m), ]

print(format(results_sorted, digits = 4))
```

```{r}
precision_data_pois <- results_poisson[, c("Reps_m", "Size_n", "Alpha", "Method", "AvgLength")]

stats_pois <- reshape(precision_data_pois,
idvar = c("Reps_m", "Size_n", "Alpha"),
timevar = "Method",
direction = "wide")

colnames(stats_pois) <- gsub("AvgLength.", "", colnames(stats_pois))

stats_pois <- stats_pois[order(stats_pois$Reps_m,
stats_pois$Size_n,
stats_pois$Alpha), ]

print(stats_pois, row.names = FALSE)

```

```{r}
coverage_data_pois <- results_poisson[, c("Reps_m", "Size_n", "Alpha", "Method", "Coverage")]

cov_pois <- reshape(coverage_data_pois,
idvar = c("Reps_m", "Size_n", "Alpha"),
timevar = "Method",
direction = "wide")

colnames(cov_pois) <- gsub("Coverage.", "", colnames(cov_pois))

cov_pois$Target <- 1 - cov_pois$Alpha

cols <- c("Reps_m", "Size_n", "Alpha", "Target",
setdiff(names(cov_pois), c("Reps_m", "Size_n", "Alpha", "Target")))
cov_pois <- cov_pois[, cols]

cov_pois <- cov_pois[order(cov_pois$Reps_m,
cov_pois$Size_n,
cov_pois$Alpha), ]

print(cov_pois, row.names = FALSE)


```

```{r}
plot_reps <- max(num_repetitions)
plot_alpha <- 0.05
plot_data_pois <- subset(results_poisson,
Reps_m == plot_reps & Alpha == plot_alpha)

methods_pois <- unique(plot_data_pois$Method)
colors <- c("red", "blue", "darkgreen")
pch_types <- 1:3

par(mfrow = c(1, 2))

y_min <- min(plot_data_pois$Coverage, 1 - plot_alpha) - 0.02
y_max <- max(plot_data_pois$Coverage, 1 - plot_alpha) + 0.02

plot(range(sample_sizes), c(y_min, y_max), type = "n",
xlab = "Sample Size (n)", ylab = "Coverage Probability",
main = paste("Coverage (Alpha =", plot_alpha, ")"))

abline(h = 1 - plot_alpha, col = "gray", lty = 2, lwd = 2)

for (i in 1:length(methods_pois)) {
sub_d <- subset(plot_data_pois, Method == methods_pois[i])
sub_d <- sub_d[order(sub_d$Size_n), ]
lines(sub_d$Size_n, sub_d$Coverage,
col = colors[i], type = "b",
pch = pch_types[i], lwd = 1.5)
}

legend("bottomright", legend = methods_pois,
col = colors, pch = pch_types, lty = 1,
cex = 0.8, bg = "white")

y_rng <- range(plot_data_pois$AvgLength, na.rm = TRUE)

plot(range(sample_sizes), y_rng, type = "n",
xlab = "Sample Size (n)", ylab = "Average Length",
main = "Interval Length (Precision)")

for (i in 1:length(methods_pois)) {
sub_d <- subset(plot_data_pois, Method == methods_pois[i])
sub_d <- sub_d[order(sub_d$Size_n), ]
lines(sub_d$Size_n, sub_d$AvgLength,
col = colors[i], type = "b",
pch = pch_types[i], lwd = 1.5)
}

legend("topright", legend = methods_pois,
col = colors, pch = pch_types, lty = 1,
cex = 0.8, bg = "white")


```

As we can see, for the Poisson case all three approaches based on normal approximation perform quite similarly.

1)  The method using the true variance (“Norm(theta)”) shows very stable coverage, staying very close to the nominal level for all sample sizes.
2)  The quadratic method (“Norm(quadratic)”), obtained by solving the inequality for theta, behaves almost identically, with coverage only slightly fluctuating around 0.95
3)  The Student–t based interval works a bit worse for the smallest sample sizes , but its performance quickly improves as n grows In terms of precision, all three methods produce intervals of almost the same average length, which decreases as the sample size increases.

# Problem 3

### (a-c)

```{r}
mu <- 10
sigma_sq_true <- 4
sigma <- sqrt(sigma_sq_true)
n_values <- c(10, 50, 100, 1000)
m_reps <- 10000 # Number of repetitions to estimate Expectation

results_var <- data.frame()

for (n in n_values) {
  
  # --- Task (a): Write code to find variance ---
  # Generate M samples of size n
  data <- matrix(rnorm(n * m_reps, mean = mu, sd = sigma), nrow = n)
  
  # Calculate sample means for each repetition (column)
  x_bar <- colMeans(data)
  
  # Calculate Sum of Squared Errors (SSE) manually: sum((xi - x_bar)^2)
  # We subtract the column mean from every element in that column
  centered_data <- data - matrix(x_bar, nrow = n, ncol = m_reps, byrow = TRUE)
  sse <- colSums(centered_data^2)
  
  # --- Task (b): Find sigma^2_n and sigma^2_{n-1} ---
  
  # Estimator 1: Biased (divide by n)
  var_est_n <- sse / n
  
  # Estimator 2: Unbiased (divide by n-1)
  var_est_n_minus_1 <- sse / (n - 1)
  
  # --- Task (c): Find the Biases ---
  # Bias = E[Estimator] - True_Parameter
  
  # Estimate E[] by taking the mean of our M repetitions
  E_var_n <- mean(var_est_n)
  E_var_n_minus_1 <- mean(var_est_n_minus_1)
  
  bias_n <- E_var_n - sigma_sq_true
  bias_n_minus_1 <- E_var_n_minus_1 - sigma_sq_true
  
  # Store results
  results_var <- rbind(results_var, data.frame(
    Sample_Size = n,
    True_Var = sigma_sq_true,
    E_n = E_var_n,
    Bias_n = bias_n,
    E_n_1 = E_var_n_minus_1,
    Bias_n_1 = bias_n_minus_1
  ))
}

# Print table with 5 digits for precision
print(format(results_var, digits = 5))
```

### (d) Comment on the results for different values of n Looking at the simulation results above: Estimator σ n 2 ​

```         
(Biased): For small sample sizes (e.g., n=10), this estimator significantly underestimates the true variance (Negative Bias). However, as n increases to 1000, the bias approaches zero. This suggests it is asymptotically unbiased. Estimator σ n−1 2 ​\
(Unbiased): The bias is consistently extremely close to 0 regardless of the sample size (fluctuating only due to simulation noise). This suggests it is an unbiased estimator for all n.
```

### (e) Derive analytically the expected value of each estimator We know that for X i ​

```         
∼N(μ,σ 2 ), the sample mean variance is Var( X ˉ )=σ 2 /n. First, let's look at the expectation of the sum of squares ∑(X i ​\
− X ˉ ) 2 :
```

$$\sum_{i=1}^n (X_i - \bar{X})^2 = \sum_{i=1}^n ((X_i - \mu) - (\bar{X} - \mu))^2 \\ = \sum_{i=1}^n (X_i - \mu)^2 - 2(\bar{X} - \mu)\sum_{i=1}^n(X_i - \mu) + n(\bar{X} - \mu)^2 $$Since $\sum(X_i - \mu) = n(\bar{X} - \mu)$: $$= \sum\_{i=1}^n (X\_i - \mu)^2 - n(\bar{X} - \mu)^2 $$Now we take the Expected Value. Recalling that $E[(Y-E[Y])^2] = \operatorname{Var}(Y)$: $$
E\left[ \sum (X_i - \bar{X})^2 \right] = \sum_{i=1}^n \operatorname{Var}(X_i) - n \operatorname{Var}(\bar{X}) $$$$ = n\sigma^2 - n\left( \frac{\sigma^2}{n} \right) = n\sigma^2 - \sigma^2 = (n-1)\sigma^2 $$Now we calculate the expected value for both estimators:

1.  For σ n 2 ​\
    :

$$E[\sigma^2_n] = E\left[ \frac{1}{n} \sum (X_i - \bar{X})^2 \right] = \frac{1}{n} (n-1)\sigma^2 = \frac{n-1}{n}\sigma^2 $$<!-- -->2. For σ n−1 2 ​\
:

$$E[\sigma^2_{n-1}] = E\left[ \frac{1}{n-1} \sum (X_i - \bar{X})^2 \right] = \frac{1}{n-1} (n-1)\sigma^2 = \sigma^2 $$

### (f) Show mathematically which estimator is unbiased

An estimator $\hat{\theta}$ is unbiased if $\operatorname{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta = 0$. 1. **For** $\sigma^2_{n-1}$: $$\operatorname{Bias} = E[\sigma^2_{n-1}] - \sigma^2 = \sigma^2 - \sigma^2 = 0$$ **Conclusion:** $\sigma^2_{n-1}$ is an **unbiased** estimator. 2. **For** $\sigma^2_n$: $$\operatorname{Bias} = E[\sigma^2_n] - \sigma^2 = \frac{n-1}{n}\sigma^2 - \sigma^2 = \sigma^2(1 - \frac{1}{n} - 1) = -\frac{\sigma^2}{n}$$ **Conclusion:** $\sigma^2_n$ is a **biased** estimator (specifically, it is negatively biased).

### (g) Comment on the results behind theoretical and practical task

The theoretical derivation perfectly explains the practical simulation results: \* The theory predicts the bias of $\sigma^2_n$ is $-\sigma^2/n$. For $n=10$ and $\sigma^2=4$, the theoretical bias is $-0.4$. Looking at our simulation table for $n=10$, the `Bias_n` column matches this value very closely. \* The theory predicts $\sigma^2_{n-1}$ has 0 bias, which matches our `Bias_n_1` column. \* The simulation confirms that while $\sigma^2_n$ is biased, the bias shrinks as $n$ grows ($\lim_{n\to\infty} -\frac{\sigma^2}{n} = 0$), confirming consistency. However, for small samples, the unbiased estimator (dividing by $n-1$) is strictly superior.\$\$

As we can see, the simulation results perfectly align with the theoretical derivation regarding the bias of variance estimators.

1.  The estimator using n in the denominator (σn2​) is **biased**: it systematically underestimates the true population variance. This negative bias is significant at small sample sizes (e.g., n=10) but shrinks towards zero as the sample size increases (asymptotically unbiased).

2.  The estimator using n−1 in the denominator (σn−12​) is **unbiased**: its average value consistently matches the true parameter σ2=4 regardless of the sample size.

3.  Consequently, for small sample sizes, using σn−12​ (Bessel's correction) is strictly necessary to avoid underestimation, while for very large samples, the difference between the two methods becomes negligible.
